\section{Related Work}

In the context of constrained RL, Liu et al. \cite{liu2021policy} \textcolor{red}{survey} various formulations in the CMDP setting and \textcolor{red}{provide an overview of corresponding model-free algorithms.}
Most existing works focus on enforcing constraints \textcolor{red}{based on} discounted cumulative cost.
Among representative methods is constrained policy optimization (CPO) \cite{achiam2017constrained}, which uses surrogate functions to approximate both the objective and the constraints.
\textcolor{red}{It then} employs a projection step to enforce constraint satisfaction.
This procedure requires a backtracking line search, \textcolor{red}{thereby making} the algorithm computationally expensive.
Another line of work includes Proximal Policy Optimization (PPO) Lagrangian and Trust Region Policy Optimization (TRPO) Lagrangian \cite{ray2019benchmarking}, which extend the PPO \cite{schulman2017proximal} and TRPO \cite{schulman2015trust} algorithms to the constrained RL setting \textcolor{red}{via} Lagrangian relaxation, reformulating the constrained policy optimization problem as an unconstrained max-min optimization problem.
By adaptively adjusting the Lagrange multiplier, these methods encourage policy updates toward satisfying the constraints.
However, since constraint violations are \textcolor{red}{inevitable} for learning a safe policy, the constraints are typically not satisfied during training.
In interior-point policy optimization (IPO) \cite{liu2020ipo}, logarithmic barrier functions are added to the objective as penalty terms to account for the constraints.
% survey 논문에서도 IPO라고 언급
While this approach is easy to implement and can handle multiple constraints, it assumes feasible iterates, which can be problematic in situations such as random agent initialization where constraint violations may occur.
Stooke et al. \cite{stooke2020responsive} \textcolor{red}{show} that in Lagrangian-based methods, the Lagrange multiplier is updated only through integral control, resulting in oscillation and overshoot issues, and propose a method that incorporates proportional and derivative terms to stabilize the updates.